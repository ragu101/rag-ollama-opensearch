# RAG Pipeline with OpenSearch & Ollama (Mistral)

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using:
- **OpenSearch** as a **vector database**
- **Ollama (Mistral)** as a **local LLM**
- **Sentence Transformer** for **text embeddings**
- **PyPDF2** for **PDF text extraction**

## ğŸš€ Features
- Extracts text from **PDF documents**
- **Chunks** the text for efficient search
- Converts text into **embeddings** using **SentenceTransformer**
- Stores embeddings in **OpenSearch** for fast retrieval
- Queries OpenSearch to retrieve **relevant chunks**
- Uses **Ollama (Mistral)** to generate answers based on retrieved context

## ğŸ› ï¸ Architecture Diagram
```mermaid
graph TD
    subgraph User
        A[5ï¸âƒ£ User Query]
    end

    subgraph RAG Pipeline
        B[1ï¸âƒ£ Extract Text from PDF]
        C[2ï¸âƒ£ Chunk Text]
        D[3ï¸âƒ£ Generate Embeddings (Sentence Transformer)]
        E[4ï¸âƒ£ Store in OpenSearch]
        F[6ï¸âƒ£ Retrieve Relevant Chunks]
        G[7ï¸âƒ£ Generate Response (Ollama Mistral)]
        H[8ï¸âƒ£ Return Final Answer]
    end

    subgraph Data Storage
        I[(ğŸ“„ PDF Documents)]
        J[(ğŸ“‚ OpenSearch Vector DB)]
    end

    I -->|Extract| B
    B --> C
    C -->|Generate Embeddings| D
    D -->|Store in OpenSearch| E
    E --> J

    A -->|Search Query| F
    F -->|Retrieve Context| J
    F -->|Pass Context| G
    G -->|Generate Response| H
    H -->|Return Answer| A
```

## ğŸ—ï¸ Installation & Setup
### 1ï¸âƒ£ Install Dependencies
```bash
pip install PyPDF2 sentence-transformers opensearch-py transformers ollama
```

### 2ï¸âƒ£ Run OpenSearch in Docker
```bash
docker run -d --name opensearch -p 9200:9200 -e "discovery.type=single-node" -e "OPENSEARCH_INITIAL_ADMIN_PASSWORD=Tr0ub4dor2025!" opensearchproject/opensearch:latest
```

### 3ï¸âƒ£ Load the Local Model in Ollama
```bash
ollama pull mistral:latest
```

## ğŸ“œ Usage
### Step 1: Ingest PDF Data
Run the Python script to extract and store document data:
```bash
python rag_setup.py
```

### Step 2: Query the System
Modify the script to ask a question:
```python
query = "Whatâ€™s in my document?"
answer = generate_answer(query)
print(answer)
```

## ğŸ“Œ Notes
- Ensure **OpenSearch** and **Ollama** are running before executing the script.
- The **PDF file** must be specified correctly in the script.
- Modify chunking size or model parameters for optimization.

